<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: December 15, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.042e26407c9e383d96a1f26d6787c686.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Devendra R. Parkar"><meta name=description content="A temporal and annotated-logic based simulation proxy that enables interpretable reinforcement learning"><link rel=alternate hreflang=en-us href=https://drparkar.github.io/project/pyreason-gym-rl/><link rel=canonical href=https://drparkar.github.io/project/pyreason-gym-rl/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0ae117fe047177e402e0184950c2f09a_3600_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0ae117fe047177e402e0184950c2f09a_3600_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:image" content="https://drparkar.github.io/project/pyreason-gym-rl/featured.png"><meta property="og:site_name" content><meta property="og:url" content="https://drparkar.github.io/project/pyreason-gym-rl/"><meta property="og:title" content="PyReason-Gym: Symbolic logic simulator for Reinforcement Learning | "><meta property="og:description" content="A temporal and annotated-logic based simulation proxy that enables interpretable reinforcement learning"><meta property="og:image" content="https://drparkar.github.io/project/pyreason-gym-rl/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-07-02T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-02T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://drparkar.github.io/project/pyreason-gym-rl/"},"headline":"PyReason-Gym: Symbolic logic simulator for Reinforcement Learning","image":["https://drparkar.github.io/project/pyreason-gym-rl/featured.png"],"datePublished":"2023-07-02T00:00:00Z","dateModified":"2023-07-02T00:00:00Z","author":{"@type":"Person","name":"Kaustuv Mukherji"},"publisher":{"@type":"Organization","name":"","logo":{"@type":"ImageObject","url":"https://drparkar.github.io/media/icon_hu0ae117fe047177e402e0184950c2f09a_3600_192x192_fill_lanczos_center_3.png"}},"description":"A temporal and annotated-logic based simulation proxy that enables interpretable reinforcement learning"}</script><title>PyReason-Gym: Symbolic logic simulator for Reinforcement Learning |</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=2ac2275319d46160ba2818619b389667><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/uploads/DParkarCV.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>PyReason-Gym: Symbolic logic simulator for Reinforcement Learning</h1><div class=article-metadata><div><span>Kaustuv Mukherji</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Devendra R. Parkar</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Lahari Pokala</span>, <span>Dyuman Aditya</span>, <span>Paulo Shakarian</span>, <span>Clark Dorman</span></div><span class=article-date>Jul 2, 2023</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.48550/arXiv.2310.06835 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/lab-v2/pyreason-rl-sim target=_blank rel=noopener>Code</a></div></div><div class=article-container><div class=article-style><video controls>
<source src=/media/pyrgsim.mp4 type=video/mp4></video><p><strong>PyReason-Gym</strong> is a new symbolic simulator introduced to enable symbolic reinforcement learning. Why is such a simulator necessary? Well, this let&rsquo;s us learn interpretable agent policies defacto and enables transfering of policies to other simulation environments. We explored these possibilities and worked on the project with following aims:</p><ol><li>Introduce and verify the new PyReason-Gym simulator for symbolic reinforcement learning.</li><li>Extend exisiting deep reinforcement learning algorithms to take advantage of symbolic representations provided by PyReason-Gym</li><li>Demonstrate ease of incorporating human-level symbolic logic to enable reinforcement learning in non-markovian dynamics(temporally non-markovian), which existing algorithms struggle with</li><li>Demonstrate ease of interpreting and transfering learned policies to other simulation environments</li></ol><p>More about the simulator and underlying inference engine can be found below:</p><div class="alert alert-note"><div><ul><li><a href=https://github.com/lab-v2/pyreason-gym target=_blank rel=noopener><strong>PyReason-Gym python package</strong></a></li><li><a href=https://github.com/lab-v2/pyreason target=_blank rel=noopener><strong>PyReason python package</strong></a></li><li>A conference paper is submitted and under review</li></ul></div></div></div><div class=article-tags><a class="badge badge-light" href=/tag/reinforcement-learning/>Reinforcement Learning</a>
<a class="badge badge-light" href=/tag/symbolic-logic-simulator/>Symbolic Logic Simulator</a>
<a class="badge badge-light" href=/tag/transfer-learning/>Transfer Learning</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F&amp;text=PyReason-Gym%3A+Symbolic+logic+simulator+for+Reinforcement+Learning" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F&amp;t=PyReason-Gym%3A+Symbolic+logic+simulator+for+Reinforcement+Learning" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=PyReason-Gym%3A%20Symbolic%20logic%20simulator%20for%20Reinforcement%20Learning&amp;body=https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F&amp;title=PyReason-Gym%3A+Symbolic+logic+simulator+for+Reinforcement+Learning" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=PyReason-Gym%3A+Symbolic+logic+simulator+for+Reinforcement+Learning%20https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fdrparkar.github.io%2Fproject%2Fpyreason-gym-rl%2F&amp;title=PyReason-Gym%3A+Symbolic+logic+simulator+for+Reinforcement+Learning" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://drparkar.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hu44f76e36240f9be7f31a7e9d4296ea84_924689_270x270_fill_q75_lanczos_center.jpg alt="Devendra R. Parkar"></a><div class=media-body><h5 class=card-title><a href=https://drparkar.github.io/>Devendra R. Parkar</a></h5><h6 class=card-subtitle>Research Assistant</h6><p class=card-text>My broad research interests include complex systems, human cognition modeling and learning theory</p><ul class=network-icon aria-hidden=true><li><a href=/uploads/DParkarCV.pdf><i class="ai ai-cv"></i></a></li><li><a href=https://github.com/devrz45 target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/devendra-parkar/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="project-related-pages content-widget-hr"><h2>Publications</h2><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/pyr-gym-rl/>Scalable Semantic Non-Markovian Simulation Proxy for Reinforcement Learning [In Press]</a></div><a href=/publication/pyr-gym-rl/ class=summary-link><div class=article-style>A temporal and annotated-logic based simulation proxy that enables interpretable reinforcement learning<br>[ Accepted at International Conference on Semantic Computing ]</div></a><div class="stream-meta article-metadata"><div><span>Kaustuv Mukherji</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Devendra R. Parkar</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Lahari Pokala</span>, <span>Dyuman Aditya</span>, <span>Paulo Shakarian</span>, <span>Clark Dorman</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/pyreason-gym-rl/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=9e6ZHJEJzgw" target=_blank rel=noopener>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2305.15596 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/pyr-gym-rl/><img src=/publication/pyr-gym-rl/featured_hucde188c3b556efef478396786c8a4bbf_115496_150x0_resize_q75_h2_lanczos_3.webp height=75 width=150 alt="Scalable Semantic Non-Markovian Simulation Proxy for Reinforcement Learning [In Press]" loading=lazy></a></div></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 Devendra Parkar. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.3322c0d94f0e691b0b24c63f4c41064b.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>